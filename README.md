 
# Naive Bayes Inference methods

In the mini-project,the basics of text analysis is illustrated using a subset of movie reviews from the rotten tomatoes database. A fundamental technique in Bayesian inference, called Naive Bayes is used.  
The Rotten tomatoes dataset is explored.A vector space model is described for the search engine. Naive Bayes inverence is explained. Next picking of hyper-parameters is demonstrated using Multinomial  Naive Bayes. Best model is used by measuring mis-predictions. Prediction is performed on a hold-out phrase. Then, TF-IDF,  is  a measure of term importance, and of how discriminative a word is in a corpus is described. An n-gram model is then evaluated. Followed by Random Forest Classifier and LatentDirichletAllocation are also explored.
In conclusion, most methods seem to yield the same results.

### Files

File|Description
---------|-------------------------------------------------------------------------------------------------------------------
[naive_bayes/code/Mini_Project_Linear_Naive_Bayes.ipynb](https://github.com/krajeshj/naive_bayes/blob/master/naive_bayes/code/Mini_Project_Naive_Bayes.ipynb )| Jupyter Notebook containing code for Bayesian Inference Unit 11.3 Springboard
[naive_bayes/data/critics.csv](https://github.com/krajeshj/naive_bayes/blob/master/naive_bayes/data/critics.csv)| csv file containing the data for mini project
 
### Directories 


Directory|Description
---------|---------------------------------------------------------------------------------------------------
[naive_bayes/data](https://github.com/krajeshj/naive_bayes/tree/master/naive_bayes/data)| contains the csv file  |
[naive_bayes/code](https://github.com/krajeshj/naive_bayes/tree/master/naive_bayes/code)| contains the python code  |

 

### References
https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example
https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d
https://ai.stanford.edu/~ang/papers/jair03-lda.pdf
